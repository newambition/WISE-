# Tactic Library: Cherry Picking

**(Tactic ID: 14)**

---

### **Tactic Detail View**

* **Clear Definition:** Cherry picking is a tactic that involves selectively presenting data, facts, examples, or cases that support a specific position while deliberately omitting contradictory or opposing evidence. This creates a misleading impression that the selected information represents the complete picture.
* **Core Mechanism:** It works by exploiting the fact that partial evidence can appear compelling in isolation. By carefully filtering information to include only what supports a desired conclusion, cherry picking creates an illusion of solid evidence while obscuring a more complex or contradictory reality. This undermines informed decision-making by presenting an incomplete basis for judgment.

---

### **Intent Spectrum Explained**

* **Legitimate Use:**
    * **Description:** Highlighting particularly relevant evidence within a balanced presentation. Focusing on specific data points while acknowledging limitations or context. Using examples to illustrate a point while maintaining transparency about selection criteria. Emphasizing strengths while also addressing weaknesses.
    * **Example:** A researcher focusing on significant findings while acknowledging study limitations. *"Our research found a 30% reduction in symptoms using this treatment approach. While these results are promising, it's important to note that our sample size was limited and further studies with diverse populations are needed to confirm these findings."* [Cite: 1.1]

* **Borderline Manipulation:**
    * **Description:** Emphasizing favorable data without equal attention to contradictory evidence. Selecting anomalous examples that support a position without noting their unrepresentative nature. Presenting information that is technically true but lacks critical context that would substantially alter its interpretation.
    * **Example:** A politician citing economic statistics selectively. *"Under my leadership, we've seen the highest job growth in a decade this quarter, showing our policies are working." (Not mentioning that overall annual trends show stagnation or that the growth follows a significant decline.)* [Cite: 1.2]

* **Blatant Manipulation:**
    * **Description:** Deliberately hiding contradictory evidence while presenting supporting information as comprehensive. Knowingly selecting unrepresentative outliers to mischaracterize a broader pattern. Creating a fundamentally false impression by strategic omission of key data points that would dramatically change conclusions.
    * **Example:** A supplement company advertising. *"Our product was shown to increase energy levels by 70% in clinical testing." (Failing to disclose that this result occurred in only 2% of participants, multiple studies showed no effect, and side effects were common.)* [Cite: 1.3]

---

### **Common Scenarios**

* **Health and Science Communication:** Selecting individual studies that support a particular health claim while ignoring the preponderance of evidence or scientific consensus to the contrary (e.g., anti-vaccination campaigns citing single retracted studies). [Cite: 2.1]
* **Political Messaging:** Highlighting economic or social statistics from specific time periods or regions that support a policy position while omitting data from other periods or areas that contradict it (e.g., crime statistics from only certain years or districts). [Cite: 2.2]
* **Product Marketing:** Featuring testimonials or reviews only from satisfied customers while hiding negative experiences, or reporting product benefits without mentioning limitations or side effects (e.g., weight loss products showing only the most successful users). [Cite: 2.3]
* **Media Reporting:** Emphasizing certain aspects of events or stories that align with a particular narrative while downplaying contradictory elements (e.g., covering violent incidents in protests while ignoring peaceful majority). [Cite: 2.4]
* **Historical Narratives:** Selecting historical events, quotations, or figures that support a particular interpretation of history while excluding contradictory evidence (e.g., nationalistic accounts that minimize historical atrocities). [Cite: 2.5]

---

### **Related Cognitive Biases**

* **Confirmation Bias:** The tendency to search for, interpret, favor, and recall information in a way that confirms one's pre-existing beliefs. Cherry picking exploits this bias by providing only the information that matches what people are predisposed to believe. [Cite: 3.1]
* **Availability Heuristic:** The tendency to overestimate the likelihood or importance of things that come readily to mind. Cherry-picked examples become mentally available, leading to overestimation of their relevance or frequency. [Cite: 3.2]
* **Anchoring Effect:** The tendency to rely too heavily on the first piece of information encountered. When presented with cherry-picked information first, subsequent judgments remain biased toward that initial anchor, even if contradictory evidence follows. [Cite: 3.3]
* **Selection Bias:** The error of selecting samples in a way that doesn't reflect the true population. Cherry picking institutionalizes this bias by deliberately selecting unrepresentative cases to support a position. [Cite: 3.4]

---

### **"How to Spot It" Checklist**

* [_] Does the presentation rely heavily on isolated examples or anecdotes rather than comprehensive data?
* [_] Are time periods, geographic regions, or study parameters suspiciously specific or narrow?
* [_] Is contradictory evidence or alternate interpretation acknowledged and addressed?
* [_] Does the source have a history of presenting only one side of complex issues?
* [_] Are metrics or measurements selectively chosen without explanation of why these particular measures are most relevant?
* [_] Is sample size or selection methodology clearly explained when statistics are presented?
* [_] Does the presentation avoid mentioning limitations, caveats, or context that might change the interpretation?

---

### **Detailed Resistance Strategies**

1. **Seek Comprehensive Data:**
   * When presented with selective examples, actively search for the broader dataset or full context.
   * Look for systematic reviews or meta-analyses that synthesize all available evidence rather than single studies or examples. [Cite: 4.1]

2. **Question Selection Criteria:**
   * Ask what criteria were used to select the presented information and whether these criteria were consistently applied.
   * Consider whether different selection criteria would yield different conclusions: "What would we see if we looked at a 10-year trend instead of just this year?" [Cite: 4.2]

3. **Identify Missing Perspectives:**
   * Deliberately seek out opposing viewpoints or contradictory evidence to balance selective presentations.
   * Ask: "What would critics say about this data?" or "What evidence would someone with the opposite view present?" [Cite: 4.3]

4. **Check for Context:**
   * Investigate whether the presented information changes meaning when additional context is provided.
   * Consider factors like historical trends, comparative benchmarks, or relevant external variables that might explain the selected data. [Cite: 4.4]

5. **Evaluate Source Credibility:**
   * Assess whether the source has incentives to present selective information or a history of balanced reporting.
   * Consider conflicts of interest that might motivate cherry picking and seek information from sources with different incentives. [Cite: 4.5]

6. **Apply Multiple Metrics:**
   * When evaluating claims, consider multiple measures of success or evidence rather than focusing on a single metric that might be cherry-picked.
   * Ask: "What other ways could we measure this phenomenon, and what would those measures show?" [Cite: 4.6]

7. **Develop Statistical Literacy:**
   * Learn basic principles of statistics and research methodology to better recognize when data has been selectively presented.
   * Understand concepts like statistical significance, sample size, selection bias, and control groups to evaluate the quality of evidence. [Cite: 4.7]

---

### **Link to Interactive Simulation/Exercise**

* **(Placeholder):** [Link to "Detecting Cherry Picking in Data" Interactive Module] - *Practice identifying cherry-picked statistics and learning to find more complete data sets across various domains including health claims, political statistics, and product marketing.*

---

### Links for Citations

Cite 1.1: https://www.nature.com/articles/s41562-019-0798-9 (Transparency in research reporting)
Cite 1.2: https://journals.sagepub.com/doi/10.1177/1532673X211021629 (Selective use of economic indicators in political communication)
Cite 1.3: https://jamanetwork.com/journals/jamainternalmedicine/article-abstract/2788685 (Misleading claims in supplement marketing)
Cite 2.1: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6137759/ (Cherry picking in anti-vaccination arguments)
Cite 2.2: https://www.tandfonline.com/doi/full/10.1080/10584609.2020.1793848 (Selective use of statistics in political campaigns)
Cite 2.3: https://www.ftc.gov/system/files/documents/reports/blurred-lines-examination-native-advertising-customer-reference/p064504_native_advertising_workshop_report_0.pdf (Selective customer testimonials in advertising)
Cite 2.4: https://journals.sagepub.com/doi/10.1177/1464884917743175 (Selective framing in protest coverage)
Cite 2.5: https://www.journals.uchicago.edu/doi/10.1086/706823 (Selective history in national narratives)
Cite 3.1: https://psycnet.apa.org/record/1998-07070-003 (Confirmation bias in information processing)
Cite 3.2: https://psycnet.apa.org/record/1974-33712-001 (Availability heuristic in judgment)
Cite 3.3: https://science.sciencemag.org/content/185/4157/1124 (Anchoring effect in decision making)
Cite 3.4: https://jamanetwork.com/journals/jama/article-abstract/1710782 (Selection bias in research)
Cite 4.1: https://www.annualreviews.org/doi/10.1146/annurev-publhealth-040617-013121 (Using systematic reviews to evaluate evidence)
Cite 4.2: https://journals.sagepub.com/doi/10.1177/0093650214534974 (Criteria transparency in data selection)
Cite 4.3: https://link.springer.com/article/10.1007/s11229-018-1692-0 (Viewpoint diversity and evidence evaluation)
Cite 4.4: https://journals.sagepub.com/doi/10.1177/0093650214534972 (Contextual factors in data interpretation)
Cite 4.5: https://www.tandfonline.com/doi/full/10.1080/1461670X.2018.1423632 (Source credibility assessment)
Cite 4.6: https://hbr.org/2019/05/the-problem-with-metrics-is-a-big-problem-for-ai (Multiple metrics for robust assessment)
Cite 4.7: https://journals.sagepub.com/doi/10.1177/0963662519850843 (Statistical literacy in public understanding)